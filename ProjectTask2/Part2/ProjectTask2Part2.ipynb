{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Recommendation (Gradient Descent Menthods)\n",
    "- $P$ is the user-factor matrix (u $x$ k)\n",
    "- $Q$ is the song-factor matrix (s $x$ k)\n",
    "- $R$ is the user-song matrix (u $x$ s)\n",
    "- $M$ is the preprocessed/ready-to-use triplet matrix (n $x$ 3)\n",
    "- $n$ is the number of lines fetched from the file\n",
    "- $u$ is the number of users\n",
    "- $s$ is the number of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configuration Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/oeken/Downloads/train_triplets.txt\"\n",
    "n = 300000\n",
    "n_test = 100     # size of the test set\n",
    "epochs = 10      # how many times to go over the whole dataset?\n",
    "delta = 0.01     # learning rate\n",
    "lambda1 = 0.0   # regularizer coeff for p\n",
    "lambda2 = 0.0   # regularizer coeff for q\n",
    "S = 1          # batch size\n",
    "k = 10           # number of latent factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Funtions Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds the corresponding bin value for a given number x \n",
    "def count_to_bin(a,b):\n",
    "    bin = 0\n",
    "    for x in range (b):\n",
    "        if a>=2**x and a<=((2**(x+1))-1):\n",
    "            return x+1\n",
    "    return b\n",
    "\n",
    "# assigns incremental IDs and creates 2-way dictionaries\n",
    "def create_dictionary(list):\n",
    "    dict_1 = {}\n",
    "    dict_2 = {}\n",
    "    count = 0;\n",
    "    for element in list:\n",
    "        if not element in dict_1:\n",
    "            dict_1[element] = count\n",
    "            dict_2[count] = element\n",
    "            count = count+1\n",
    "    return dict_1, dict_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reads n triplets from given file and returns them in a list\n",
    "def read_triplets(path, n):\n",
    "    with open(path) as infile:\n",
    "        count = 0;\n",
    "        triplets = []        \n",
    "        for line in infile:\n",
    "            temp_list=[]\n",
    "            count = count+1\n",
    "            temp_list = line.split()\n",
    "            triplets.append(temp_list)\n",
    "            if count==n:\n",
    "                break        \n",
    "    return triplets\n",
    "\n",
    "\n",
    "# removes triplets containing entities 5 or less occurrences\n",
    "def elim_five_or_less(triplets):\n",
    "    \n",
    "    while 1 : \n",
    "        min_listeners = triplets.groupby('users').count().min()[0]\n",
    "        min_songs = triplets.groupby('songs').count().min()[0]\n",
    "        triplets = triplets.groupby('users').filter(lambda x: len(x) > 5)\n",
    "        triplets = triplets.groupby('songs').filter(lambda x: len(x) > 5)\n",
    "        if min_listeners>5 and min_songs>5:\n",
    "            break;\n",
    "    return triplets\n",
    "\n",
    "\n",
    "# assigns ids to users and songs and binifies the play counts\n",
    "def get_ids_and_bins(M_raw):\n",
    "    M = M_raw.copy()\n",
    "    users = M[:,0] #first column represents the users\n",
    "    songs = M[:,1] #second column represents the songs\n",
    "    ud1, ud2 = create_dictionary(users) #gives incremental integer values to all users\n",
    "    sd1, sd2 = create_dictionary(songs) #gives incremental integer values to all songs\n",
    "\n",
    "    M[:,2] = [count_to_bin(x , 7) for x in M[:,2]] #bin representation of the counts\n",
    "    M[:,1] = [sd1[x] for x in M[:,1]] #incremental represantation of the songs\n",
    "    M[:,0] = [ud1[x] for x in M[:,0]] #incremental represantation of the listeners\n",
    "    return M, ud1, ud2, sd1, sd2\n",
    "\n",
    "\n",
    "# given an instance of p finds associated q's with it, and vice-versa. makes use of dicts\n",
    "def assoc_pq(M):\n",
    "    p_to_q = dict()    \n",
    "    q_to_p = dict()\n",
    "    for row in M:\n",
    "        if row[0] in p_to_q:\n",
    "            tup = p_to_q[row[0]]\n",
    "            tup[0].append(row[1])\n",
    "            tup[1].append(row[2])\n",
    "        else:\n",
    "            p_to_q[row[0]] = [[row[1]], [row[2]]]\n",
    "            \n",
    "        if row[1] in q_to_p:\n",
    "            tup = q_to_p[row[1]]\n",
    "            tup[0].append(row[0])\n",
    "            tup[1].append(row[2])\n",
    "        else:\n",
    "            q_to_p[row[1]] = [[row[0]], [row[2]]]                    \n",
    "    return p_to_q, q_to_p\n",
    "\n",
    "def error(P, Q, M):\n",
    "    e = 0\n",
    "    for row in M:\n",
    "        e += (row[2] - P[row[0],:].dot(Q[row[1],:]))**2        \n",
    "    e += lambda1 * np.linalg.norm(P)\n",
    "    e += lambda2 * np.linalg.norm(Q)\n",
    "    return e, e/M.shape[0]\n",
    "\n",
    "def rmse(P, Q, M):\n",
    "    r = 0\n",
    "    for row in M:\n",
    "        r += (row[2] - P[row[0],:].dot(Q[row[1],:]))**2\n",
    "    r /= M.shape[0]\n",
    "    r = np.sqrt(r)\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read $n$ triplets from the given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>songs</th>\n",
       "      <th>play_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      users               songs play_counts\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9           1\n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n",
       "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22           1\n",
       "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = read_triplets(path, n)\n",
    "triplets = pd.DataFrame(triplets, columns=['users','songs','play_counts'])\n",
    "triplets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(triplets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recursively eliminate triplets containing users/songs whose occurrence is less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>songs</th>\n",
       "      <th>play_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBSUJE12A6D4F8CF5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       users               songs play_counts\n",
       "0   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n",
       "2   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n",
       "6   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBSUJE12A6D4F8CF5           2\n",
       "9   b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1\n",
       "10  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_eliminated = elim_five_or_less(triplets)\n",
    "triplets_eliminated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171225, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_eliminated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Assign IDs to users/songs and binify the play counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of triplets: 171225\n",
      "# of users: 5693\n",
      "# of songs: 10966\n",
      "Total rating slots: 62429438\n",
      "Data ratio: 0.0027\n"
     ]
    }
   ],
   "source": [
    "M_raw = np.asarray(triplets_eliminated) #convert list to ndarray\n",
    "M_raw[:,2] = list(map(int, M_raw[:,2])) #parse the string counts to integer\n",
    "\n",
    "M, ud1, ud2, sd1, sd2 = get_ids_and_bins(M_raw)\n",
    "u = len(ud1)  # number of users\n",
    "s = len(sd1)  # number of songs\n",
    "n_new = len(M)\n",
    "print('# of triplets: %d' % (n_new))\n",
    "print('# of users: %d' % (u))\n",
    "print('# of songs: %d' % (s))\n",
    "print('Total rating slots: %d' % (u*s))\n",
    "print('Data ratio: %.4f' % (n_new/(u*s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Synthetic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# synthetic götten uydurma data\n",
    "# see --> http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "# u = 5\n",
    "# s = 4\n",
    "# M = np.array([[0,0,5],\n",
    "#                 [0,1,3],\n",
    "#                  [0,3,1],\n",
    "#                  [1,0,4],\n",
    "#                  [1,3,1],\n",
    "#                  [2,0,1],\n",
    "#                  [2,1,1],\n",
    "#                  [2,3,5],                 \n",
    "#                  [3,0,1],\n",
    "#                  [3,3,4],\n",
    "#                  [4,1,1],\n",
    "#                  [4,2,5],                                  \n",
    "#                  [4,3,4]])\n",
    "# n_new = 13\n",
    "# print('# of triplets: %d' % (n_new))\n",
    "# print('# of users: %d' % (u))\n",
    "# print('# of songs: %d' % (s))\n",
    "# print('Total rating slots: %d' % (u*s))\n",
    "# print('Data ratio: %.4f' % (n_new/(u*s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Seperate data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape (100,)\n",
      "Trai set shape (171225,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "all_indices = np.arange(n_new)\n",
    "np.random.shuffle(all_indices)\n",
    "test_indices = all_indices[:n_test]\n",
    "#trai_indices = all_indices[n_test:]\n",
    "trai_indices = all_indices # uncomment for synthetic data\n",
    "print('Test set shape', test_indices.shape)\n",
    "print('Trai set shape', trai_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initialize $P$ and $Q$ matrices + Compute batch count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initPQ(k):    \n",
    "    np.random.seed(110)\n",
    "    P = np.random.rand(u,k) # init P\n",
    "    Q = np.random.rand(s,k) # init Q\n",
    "\n",
    "    print('P shape: ', P.shape)\n",
    "    print('Q shape: ', Q.shape)\n",
    "    #errors = [error(P,Q,M)]\n",
    "    #print('Initial error: ', errors)\n",
    "\n",
    "    print()\n",
    "\n",
    "    batch_count = int(n_new / S)\n",
    "    print('Train count:', trai_indices.size)\n",
    "    print('Batch size: %d' % S)\n",
    "    print('Batch count: %d' % batch_count)\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define gradient descent with given batch size, $S$\n",
    "* Note that if $S = <$size of training data$>$ then the algorithm reduces to Standard Gradient Descent\n",
    "* Note that if $S = 1$ then the algorithm reduces the Classical Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GD(epochs, P, Q, M, S):\n",
    "    errors = []\n",
    "    errors.append(error(P,Q,M))\n",
    "    \n",
    "    rmses = []\n",
    "    rmses.append(rmse(P,Q,M))\n",
    "    \n",
    "    t = time.process_time()\n",
    "    print('i. E(P,Q) = %.3f, %.3f' % errors[0])\n",
    "\n",
    "    for e in range(epochs):  # how many times to go over the whole dataset\n",
    "        t_epoch = time.process_time()\n",
    "        np.random.shuffle(trai_indices)  # permute the training data\n",
    "        for b in range(batch_count):  # for each batch\n",
    "\n",
    "            batch = trai_indices[b*S:b*S+S]  # fetch the next training data indices\n",
    "            M_b = M[batch]\n",
    "            p_grad = {}\n",
    "            q_grad = {}\n",
    "\n",
    "            for row in M_b:  # compute gradients\n",
    "                p = row[0]\n",
    "                q = row[1]\n",
    "                r = row[2]\n",
    "                p_vec = P[p,:]\n",
    "                q_vec = Q[q,:]\n",
    "                term = (r - p_vec.dot(q_vec))\n",
    "\n",
    "                if p in p_grad:\n",
    "                    p_grad[p] += term * q_vec\n",
    "                else:\n",
    "                    p_grad[p] = term * q_vec - (lambda1 * p_vec)\n",
    "\n",
    "                if q in q_grad:\n",
    "                    q_grad[q] += term * p_vec\n",
    "                else:\n",
    "                    q_grad[q] = term * p_vec - (lambda2 * q_vec)\n",
    "\n",
    "\n",
    "            for p in p_grad.keys():\n",
    "                P[p,:] += delta * p_grad[p]\n",
    "\n",
    "            for q in q_grad.keys():\n",
    "                Q[q,:] += delta * q_grad[q]\n",
    "\n",
    "        error_current = error(P, Q, M)\n",
    "        errors.append(error_current)\n",
    "        rmse_current = rmse(P,Q,M)\n",
    "        rmses.append(rmse_current)\n",
    "        print('%d. E(P,Q) = %.3f, %.3f -- time: %.2f' % (e, error_current[0], error_current[1], time.process_time()-t_epoch))\n",
    "\n",
    "\n",
    "    elapsed_time = time.process_time() - t\n",
    "    print('%d Epochs, Total seconds: %f' % (epochs, elapsed_time))\n",
    "    return errors, rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SGD ($S = 1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P shape:  (5693, 8)\n",
      "Q shape:  (10966, 8)\n",
      "\n",
      "Train count: 171225\n",
      "Batch size: 1\n",
      "Batch count: 171225\n",
      "i. E(P,Q) = 269582.674, 1.574\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-135f97f43997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitPQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-cbd6dde966ea>\u001b[0m in \u001b[0;36mGD\u001b[0;34m(epochs, P, Q, M, S)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrai_indices\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# permute the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrai_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# fetch the next training data indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_count' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "S = 1\n",
    "k = 8\n",
    "\n",
    "P, Q = initPQ(k)\n",
    "(e1,r1) = GD(epochs, P, Q, M, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Modified SGD ($1<S<n$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "S = 1\n",
    "k = 8\n",
    "\n",
    "P, Q = initPQ(k)\n",
    "(e2,r2) = GD(epochs, P, Q, M, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standard GD ($S = n$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "S = 1\n",
    "k = 8\n",
    "P, Q = initPQ(k)\n",
    "(e3,r3) = GD(epochs, P, Q, M, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(P.dot(Q.T)).head(5)\n",
    "# see --> https://hec.su/lWz"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
